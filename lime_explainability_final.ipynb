{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rl132PDOOgjk"
   },
   "outputs": [],
   "source": [
    "#import model\n",
    "#!pip install lime\n",
    "#!pip install tensorflow transformers\n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4ArkEYGOnlr",
    "outputId": "c85c8ff0-dfca-4f30-8ebf-34f6de716437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 17:03:36.781456: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-25 17:03:36.782125: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids_layer (InputLayer)   [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask_layer (InputLay  [(None, None)]      0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids_layer[0][0]',        \n",
      " el)                            thPoolingAndCrossAt               'attention_mask_layer[0][0]']   \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, None, 256)    590080      ['tf_roberta_model[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, None, 256)    0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, None, 256)    0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 256)          525312      ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 256)          0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 6)            1542        ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125,762,566\n",
      "Trainable params: 125,762,566\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LOAD IN MODEL (if needed)\n",
    "\n",
    "##One thing is check that the classification layer is of size 5 and not size 6.\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import tensorflow as tf\n",
    "\n",
    "checkpoint = 'roberta-base'\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "file_path = \"../models/roberta_model_final.keras\"\n",
    "\n",
    "# Load the model\n",
    "roberta_classification_model = tf.keras.models.load_model(file_path, custom_objects={'TFRobertaModel': TFRobertaModel})\n",
    "\n",
    "# Display the model summary\n",
    "roberta_classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KUAfDrGROnz7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv('../efcamdat_test_data.csv')\n",
    "\n",
    "test_data['cefr_numeric'] = test_data['cefr_numeric'].astype('category')\n",
    "\n",
    "test_texts = test_data[\"text\"]\n",
    "test_labels = test_data[\"cefr_numeric\"].apply(lambda x: int(x)-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8VzZEtZFsvi",
    "outputId": "c16f9723-0bcf-4f02-cff9-1784eb1a903c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data[\"cefr_numeric\"].value_counts()\n",
    "num_classes = test_labels.nunique()\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "B-iUR_tSOoJF"
   },
   "outputs": [],
   "source": [
    "test_instance_index = 1\n",
    "test_instance = test_texts.iloc[test_instance_index]\n",
    "true_label = test_labels.iloc[test_instance_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CQPBtB0u-ijj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 1 True Label: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text: {test_instance_index} True Label: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3vgPfxpeUZ_",
    "outputId": "bc50914a-ffb7-4545-9d02-8f1d01442332"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielskahill/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "test_instance_no_stopwords = remove_stopwords(test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "PRCGYEunh2td",
    "outputId": "6581c6d7-cd43-417a-9256-f1853773fd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! name Julia I'll talk rotine. afternoon, Sean plays baskteboll every day, Granny laundry every Tuesday walk dog. feed dog 8pm every day. Granny gardening morning. 5pm, Sean watches movies Saturdays fees dog every day. 6pm Granny sets table Sean plays computer games.\n"
     ]
    }
   ],
   "source": [
    "print(test_instance_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TzDpuYPOogZ",
    "outputId": "f322e902-75d6-46c1-a96c-8f214ff8969a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 1\n",
      "True label: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "\n",
    "def predict_prob(text):\n",
    "    encodings = roberta_tokenizer(text, truncation=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH, return_tensors='tf')\n",
    "    inputs = {\n",
    "        'input_ids_layer': encodings['input_ids'],\n",
    "        #'token_type_ids': encodings['token_type_ids'],\n",
    "        'attention_mask_layer': encodings['attention_mask']\n",
    "    }\n",
    "    predictions = roberta_classification_model(inputs, training=False)\n",
    "    return tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Get the predicted label for the test instance\n",
    "predicted_label = predict_prob(test_instance_no_stopwords)[0]\n",
    "\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "print(f\"True label: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHFYhvtCOy9N"
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Initialize the LIME text explainer\n",
    "explainer = LimeTextExplainer(class_names=list(test_labels.cat.categories))\n",
    "\n",
    "# Explain the model's prediction on the test instance\n",
    "exp = explainer.explain_instance(test_instance_no_stopwords, predict_prob, num_features=5)\n",
    "\n",
    "# Display the explanation with true and predicted labels\n",
    "print(f\"True label: {test_labels.cat.categories[true_label]}\")\n",
    "print(f\"Predicted label: {test_labels.cat.categories[predicted_label]}\")\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFkOZyBGOzRU"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "weights = OrderedDict(exp.as_list())\n",
    "lime_weights = pd.DataFrame({\"words\": list(weights.keys()), \"weights\": list(weights.values())})\n",
    "\n",
    "sns.barplot(x = \"words\", y = \"weights\", data = lime_weights)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title(\"Sample {} features weights given by LIME\".format(test_instance_index))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbfkcantkJ-M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
